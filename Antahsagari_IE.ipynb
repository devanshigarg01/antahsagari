{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Antahsagari_IE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6YE6KXWPn2I",
        "outputId": "7edf2bd5-0f30-4f9a-bca1-8954f20b1a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2OJDmnLPu_N",
        "outputId": "58b91fde-425a-4397-f92f-25d5e6933cd8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "train_transformer = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "  def __init__(self, input_dir, clear_img_dir, transform ):\n",
        "  \n",
        "    self.filenames = os.listdir(input_dir)\n",
        "    self.filenames = [os.path.join(input_dir, f) for f in self.filenames if f.endswith('.jpg')]\n",
        "    self.filenames.sort()\n",
        "    \n",
        "    self.clear_img_file = os.listdir(clear_img_dir)\n",
        "    self.clear_img_file =[os.path.join(clear_img_dir, f) for f in self.clear_img_file if f.endswith('.jpg')]\n",
        "    self.clear_img_file.sort()\n",
        "    self.transform = transform\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    input_image = Image.open(self.filenames[index]) \n",
        "    input_image = self.transform(input_image)\n",
        "\n",
        "    clear_image = Image.open(self.clear_img_file[index])\n",
        "    clear_image = self.transform(clear_image)\n",
        "    return input_image, clear_image\n",
        "    \n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.filenames)\n"
      ],
      "metadata": {
        "id": "MFL_6Z_KSjq1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "imagedir = '/content/drive/MyDrive/Colab Notebooks/Paired/underwater_imagenet/trainA'\n",
        "clearimagedir = '/content/drive/MyDrive/Colab Notebooks/Paired/underwater_imagenet/trainB'\n",
        "\n",
        "dataset = ImageDataset( imagedir,clearimagedir, train_transformer)\n",
        "\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=1,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)\n",
        "\n",
        "input_img, clear_img = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "tNfi62nZj_Yv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PreProcessing(input_img):\n",
        "  \n",
        "  temp = input_img\n",
        "  \n",
        "  mu_i = torch.mean(temp, dim = (2,3), keepdim=True)\n",
        "\n",
        "  sigma_i = torch.std(temp, dim = (2,3), keepdim=True)\n",
        "\n",
        "  I_centered = input_img.sub_(mu_i)\n",
        "  mu_sigma_cat = torch.cat((mu_i, sigma_i), dim = 1)\n",
        "\n",
        "  return I_centered, mu_i, mu_sigma_cat"
      ],
      "metadata": {
        "id": "wXdkc5JjrTDl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TotalNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(TotalNet, self).__init__()\n",
        "    self.bias_layer = nn.Linear(3, 16)\n",
        "\n",
        "    #GLOBAL NET\n",
        "    input_size =3\n",
        "    hidden_size=16\n",
        "    output_size=3\n",
        "    self.gl1 = nn.Linear(input_size, hidden_size)\n",
        "    self.fc1 = nn.ReLU()\n",
        "    self.gl2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.fc2 = nn.ReLU()\n",
        "    self.gl3 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.fc3 = nn.ReLU()\n",
        "    self.gl4 = nn.Linear(hidden_size*3, output_size)\n",
        "    self.fc4 = nn.Sigmoid()\n",
        "\n",
        "    #LOCAL_NET\n",
        "    input_channels=3\n",
        "    num_channels=16\n",
        "    output_channels=3\n",
        "    self.ll1 = nn.Conv2d(input_channels, num_channels, kernel_size = 3, padding=1  ,bias = False) \n",
        "    self.conv1 = nn.ReLU()\n",
        "    self.ll2 = nn.Conv2d(num_channels, num_channels, kernel_size = 3, padding=1  ,bias = False)\n",
        "    self.conv2 = nn.ReLU()\n",
        "    self.ll3 = nn.Conv2d(num_channels, num_channels, kernel_size = 3, padding=1  ,bias = False)\n",
        "    self.conv3 = nn.ReLU()\n",
        "    self.ll4 = nn.Conv2d(num_channels*3, output_channels,kernel_size=3, padding=1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    print(\"======================= Image ====================\")\n",
        "    imshow(torchvision.utils.make_grid(x.cpu().data))\n",
        "    I_centered, mu_i, mu_sigma_cat = PreProcessing(x)\n",
        "   \n",
        "    print(\"======================= I-centered ====================\")\n",
        "    imshow(torchvision.utils.make_grid(I_centered.cpu().data))\n",
        "    #print('mu_sigma_cat shape:',mu_sigma_cat.shape, 'mu_i shape :' , mu_i.shape)\n",
        "    new = torch.reshape(mu_sigma_cat,(1,1,6))\n",
        "    #trp = torch.transpose(new,1,2)\n",
        "    mu_i = torch.reshape(mu_i,(1,1,3))\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    GLOBAL NET\n",
        "    \"\"\"\n",
        "    # print(trp.shape)\n",
        "    x=mu_i\n",
        "    out = self.gl1(x)\n",
        "    h1 = self.fc1(out)\n",
        "    out = self.gl2(h1)\n",
        "    h2 = self.fc2(out)\n",
        "    out = self.gl3(h2)\n",
        "    h3 = self.gl3(out)\n",
        "    # print(\"h3\",h3.shape)\n",
        "    ct = torch.cat((h1,h2,h3), dim = 2 )\n",
        "    # print(\"concat global \",ct.shape)\n",
        "    delta_mu_i = self.gl4(ct)\n",
        "    mu_final = self.fc4(delta_mu_i.add(mu_i))\n",
        "\n",
        "\n",
        "    self.bias = self.bias_layer(delta_mu_i)\n",
        "    # print(\"delta_mu :\",delta_mu_i.shape)\n",
        "    # print(\"mu :\",mu_i.shape)\n",
        "    \n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    LOCAL NET\n",
        "    \"\"\"\n",
        "    x=I_centered\n",
        "    out = self.ll1(x) \n",
        "    # print(out.shape)\n",
        "    out +=torch.reshape(self.bias,(16,1,1))\n",
        "    H1 = self.conv1(out)\n",
        "    out = self.ll2(H1) + torch.reshape(self.bias,(16,1,1))\n",
        "    H2 = self.conv2(out)\n",
        "    out = self.ll3(H2) + torch.reshape(self.bias,(16,1,1))\n",
        "    H3 = self.conv3(out)\n",
        "    J_centered = self.ll4(torch.cat((H1,H2,H3), dim = 1))\n",
        "    print(\"======================= J_Centered ====================\")\n",
        "    imshow(torchvision.utils.make_grid(J_centered.cpu().data))\n",
        "\n",
        "    #mu_final = torch.sigmoid(mu_i.add(delta_mu_i))\n",
        "    # print(\"mu_final\",mu_final.shape)\n",
        "    J_final = J_centered.add(torch.reshape(mu_final,(3,1,1)))\n",
        "    print(\"======================= JFINAL ====================\")\n",
        "    imshow(torchvision.utils.make_grid(J_final.cpu().data))\n",
        "    \n",
        "    print(\"mu_i\",mu_i)\n",
        "    print(\"delta_mui\",delta_mu_i)\n",
        "    print(\"mu_final\",mu_final)\n",
        "\n",
        "    \n",
        "\n",
        "    return J_final\n",
        "\n"
      ],
      "metadata": {
        "id": "LjgdxlUtsp6T"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lVRFsAjDs7pz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}